{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e3458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:52:08.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.settings\u001b[0m:\u001b[36mload_settings\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mLoading settings from the ZenML secret store.\u001b[0m\n",
      "\u001b[32m2025-05-09 22:52:08.388\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mllm_engineering.settings\u001b[0m:\u001b[36mload_settings\u001b[0m:\u001b[36m99\u001b[0m - \u001b[33m\u001b[1mFailed to load settings from the ZenML secret store. Defaulting to loading the settings from the '.env' file.\u001b[0m\n",
      "\u001b[32m2025-05-09 22:52:08.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.infrastructure.db.mongo\u001b[0m:\u001b[36m__new__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mConnection to MongoDB with URI successful: mongodb://llm_engineering:llm_engineering@127.0.0.1:27017\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mPyTorch version 2.2.2 available.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:52:10.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.infrastructure.db.qdrant\u001b[0m:\u001b[36m__new__\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mConnection to Qdrant DB with URI successful: localhost:6333\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mLoad pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianadler/Library/Caches/pypoetry/virtualenvs/llm-engineering-iiO-s7sh-py3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from llm_engineering.application.rag.retriever import ContextRetriever\n",
    "import tempfile \n",
    "import os\n",
    "import webdataset as wds\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbad8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ContextRetriever(mock=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b82ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    documents = retriever.search(query, k =6)\n",
    "    grouped = retriever.group_by_title(documents)\n",
    "    reranked = retriever.rerank(query, grouped, keep_top_k=1)\n",
    "    \n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd4ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import tempfile\n",
    "import os\n",
    "import subprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6e1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_clip_from_youtube(youtube_url, start_time, end_time):\n",
    "    # 1. Create a temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    full_video_path = os.path.join(temp_dir, \"full_video.mp4\")\n",
    "    clip_path = os.path.join(temp_dir, \"clip.mp4\")\n",
    "\n",
    "    # 2. Download the full YouTube video using yt_dlp\n",
    "    ydl_opts = {\n",
    "        'outtmpl': full_video_path,\n",
    "        'format': 'mp4',\n",
    "        'quiet': True,\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "\n",
    "    # 3. Slice the desired clip using moviepy\n",
    "    ffmpeg_cmd = [\n",
    "        'ffmpeg',\n",
    "        '-i', full_video_path,\n",
    "        '-ss', str(start_time),\n",
    "        '-to', str(end_time),\n",
    "        '-c', 'copy',  # This copies the streams directly (no re-encoding)\n",
    "        clip_path\n",
    "    ]\n",
    "\n",
    "    # Run the ffmpeg command\n",
    "    subprocess.run(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    return clip_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5755b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_display(query):\n",
    "    documents = search(query)\n",
    "    clips = []\n",
    "    titles = []\n",
    "    # for doc in documents:\n",
    "    #     clip_path = extract_clip_from_youtube(doc.url, doc.start_time, doc.end_time)\n",
    "    #     clip_tuple = (clip_path, doc.title)  \n",
    "    #     clips.append(clip_tuple)\n",
    "    #     titles.append(doc.title)\n",
    "\n",
    "    clip_path =extract_clip_from_youtube(documents[0].url, documents[0].start_time, documents[0].end_time)\n",
    "    print(clip_path)\n",
    "    return clip_path\n",
    "\n",
    "\n",
    "def interface(query):\n",
    "    clips, titles = search_and_display(query)\n",
    "    \n",
    "    # Gradio Interface: Video component to display clips with their labels\n",
    "    return gr.Video(value =clips, label = titles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2055499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\u001b[1;35mHTTP Request: GET \u001b[0m\u001b[34mhttp://127.0.0.1:7861/gradio_api/startup-events\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mHTTP Request: HEAD \u001b[0m\u001b[34mhttp://127.0.0.1:7861/\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mHTTP Request: GET \u001b[0m\u001b[34mhttps://api.gradio.app/pkg-version\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:12.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mQuery  = Using only the videos, explain how ResNets Works\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llm_engineering.domain.queries.Query'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a45935b82954abcab8352e545e5bfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:12.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.preprocessing.dispatchers\u001b[0m:\u001b[36mdispatch\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mData embedded successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mHTTP Request: POST \u001b[0m\u001b[34mhttp://localhost:6333/collections/embedded_clips/points/search\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:12.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1m2 documents retrieved successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572672558faf4662b03813b33a4cf390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:12.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m2 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d1baf0cc634dd1a5de2a146d80ad37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:12.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m1 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/hmlqr79n3czgrmldxwy475lr0000gn/T/tmpq9hhm4x1/clip.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:51.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mQuery  = Using only the videos, explain how ResNets Works\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llm_engineering.domain.queries.Query'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f25a01007a4414a6702d7023a3a079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:51.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.preprocessing.dispatchers\u001b[0m:\u001b[36mdispatch\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mData embedded successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mHTTP Request: POST \u001b[0m\u001b[34mhttp://localhost:6333/collections/embedded_clips/points/search\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:51.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1m2 documents retrieved successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fe39d48c214381a6ea805087b2c946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:51.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m2 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025bf78886bc4fc09667a038693f529b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:54:51.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m1 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/hmlqr79n3czgrmldxwy475lr0000gn/T/tmp970gwt4o/clip.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:55:39.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mQuery  = Using the videos, explain the advantages of CNNs over fully connected networks\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llm_engineering.domain.queries.Query'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5eb71423d243de9a2e022b195e7fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:55:39.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.preprocessing.dispatchers\u001b[0m:\u001b[36mdispatch\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mData embedded successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mHTTP Request: POST \u001b[0m\u001b[34mhttp://localhost:6333/collections/embedded_clips/points/search\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:55:39.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1m2 documents retrieved successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3cee199bf54c45a1e6a6aa136c7c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:55:39.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m2 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666c46cb3f514623a1874555cd09595b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:55:39.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m1 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/hmlqr79n3czgrmldxwy475lr0000gn/T/tmphuc0yycp/clip.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:19.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mQuery  = Using the videos, explain the binary cross entropy loss function\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llm_engineering.domain.queries.Query'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bb43b23a4b47d3841047aa7e6ad63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:19.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.preprocessing.dispatchers\u001b[0m:\u001b[36mdispatch\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mData embedded successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mHTTP Request: POST \u001b[0m\u001b[34mhttp://localhost:6333/collections/embedded_clips/points/search\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:19.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1m2 documents retrieved successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7bb6b6f62942cc9b7123f4480594f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:20.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m2 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfe854838e2400c8648f8c2dcd57de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:20.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m1 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/hmlqr79n3czgrmldxwy475lr0000gn/T/tmpw32zyg94/clip.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[32m2025-05-09 22:56:57.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mQuery  = Using the videos, explain what logistic regression is\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llm_engineering.domain.queries.Query'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440a7d962e284f798e59fc7cb8468313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:57.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.preprocessing.dispatchers\u001b[0m:\u001b[36mdispatch\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mData embedded successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mHTTP Request: POST \u001b[0m\u001b[34mhttp://localhost:6333/collections/embedded_clips/points/search\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:58.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36msearch\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1m2 documents retrieved successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2c1619203a47109f99efac46cd6b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:58.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m2 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e608424d186c41fa9c747bce89753d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-09 22:56:58.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllm_engineering.application.rag.retriever\u001b[0m:\u001b[36mrerank\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m1 documents reranked successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/hmlqr79n3czgrmldxwy475lr0000gn/T/tmp6705trbj/clip.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(fn=search_and_display\n",
    "             , inputs=\"text\", outputs=gr.Video()).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972e89d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering-iiO-s7sh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
